"""Pod list and stats for monitored workloads

Quick overview of all pods being monitored with
instructions to learn how to write pxl scripts

"""

import px
# ----------------------------------------------------------------
# Visualization Variables - No need to edit for basic configuration.
# ----------------------------------------------------------------

# You can use this view to switch to other K8s objects
# (options: 'pod', 'service')
k8s_object = 'pod'
# Window in seconds within which to aggregate metrics.
window_s = 10
# k8s_object column is assigned to this and is used in vis spec.
split_series_name = 'k8s'
px.Pod = str
# ----------------------------------------------------------------


# ----------------------------------------------------------------
# Visualization functions:
#
# These functions are formatted and ready for use in
# the visualization speciciation, vis.json.
# ----------------------------------------------------------------
def pod_let(start: str, pod: px.Pod):
    """ Calculates LET time-series for pods that matchpod.
    Args:
    @start: The timestamp of data to start at.
    @pod: the partial/full-name of the pod to
        calculate LET.

    Returns: DataFrame of the LET stats for pods that
        match @pod.
    """
    df = make_http_table(start)
    # Calculate LET of svc(s) (k8s_object) over the time window ('timestamp')
    # after filtering for matching svcs.
    matching_df = df[px.contains(df[k8s_object], pod)]
    let_df = calc_LET(matching_df, [k8s_object, 'timestamp'])

    # Format and organize resulting columns.
    let_df[split_series_name] = let_df[k8s_object]
    let_df = let_df[['time_', split_series_name, 'latency_p50',
                     'latency_p90', 'latency_p99', 'error_rate', 'rps', 'bytes_per_s']]
    return let_df


def summary_pod_let(start: str, pod: px.Pod):
    """ Calculates LET summary for pods matching pod filter.

    Args:
    @start: The timestamp of data to start at.
    @pod: the partial/full-name of the pod to
        calculate LET.

    Returns: DataFrame of the LET summary for pods that
        match @pod.
    """
    df = pod_let(start, pod)
    summary_df = summarize_LET(df, [split_series_name])
    return summary_df


def resource_stats(start: str, pod: px.Pod):
    """ Gets the resource usage of matching pods.

    Args:
    @start: Starting time of the data to examine.
    @pod: The partial name of the pod(s) to display data for.

    Returns: A DataFrame of resource usage per pod matched in the passed
        in filters.
    """
    # Query process stats in target window
    rsrc_df = px.DataFrame(table='process_stats', start_time=start)
    rsrc_df = format_resource_table(rsrc_df)
    # Filter down to specified objects
    rsrc_df = rsrc_df[px.contains(rsrc_df[k8s_object], pod)]
    rsrc_df = calc_resource(rsrc_df)
    return rsrc_df


# ----------------------------------------------------------------
# Utility functions:
#
# These are shared functions. We plan to support imports in v0.3,
# which will allow these functions to be shared across multiple
# scripts.
# ----------------------------------------------------------------
def make_http_table(start: str):
    """ Makes the HTTP table given the passed in start.

    The data necessary to compute HTTP level svc information is located in the
    http_events table. We filter and aggregate data from this table to compute the
    required metrics.

    Args:
    @start: The timestamp of data to start at.

    Returns: DataFrame of HTTP events with formatted columns.
    """
    # The data necessary to compute HTTP level svc information is located in the
    # http_events table. We filter and aggregate data from this table to compute the
    # required metrics.
    df = px.DataFrame(table='http_events', start_time=start)
    df = format_http_table(df)
    return df


def format_events_table(spans_df, latency_ns_col):
    """ Format data and add semantic columns in event tables

    Unifies latency column to 'latency_ms', adds a binned
    timestamp field to aggregate on, and adds the svc
    (k8s_object) as a semantic column.

    Works on "mysql_events" and "http_events"

    Args:
    @df: the input events table
    @latency_ns_col: the name of the latency column in @df.

    Returns: formatted events DataFrame
    """
    spans_df.latency_ms = spans_df[latency_ns_col] / 1.0E6
    spans_df = spans_df[spans_df['latency_ms'] < 10000.0]
    spans_df.timestamp = px.bin(spans_df.time_, px.seconds(window_s))
    spans_df[k8s_object] = spans_df.ctx[k8s_object]
    spans_df = spans_df[spans_df[k8s_object] != '']
    return spans_df


def format_http_table(spans_df):
    """ Formats HTTP events tables

    Unifies latency column to 'latency_ms', adds a binned
    timestamp field to aggregate on, and adds the svc
    (k8s_object) as a semantic column.

    Works on "mysql_events" and "http_events".

    Args:
    @spans_df: the input http_events table.

    Returns: formatted HTTP events DataFrame.
    """
    spans_df = format_events_table(spans_df, 'http_resp_latency_ns')
    spans_df.resp_size = px.length(spans_df.http_resp_body)
    spans_df.failure = spans_df.http_resp_status >= 400

    return spans_df


def calc_LET(spans_df, groups):
    # Aggregate values over the window.
    spans_df = spans_df.groupby(groups).agg(
        latency_quantiles=('latency_ms', px.quantiles),
        error_rate_per_window=('failure', px.mean),
        throughput_total=('latency_ms', px.count),
        bytes_total=('resp_size', px.sum)
    )

    # Convert the aggregated values into rates.
    spans_df.error_rate = spans_df.error_rate_per_window * \
        spans_df.throughput_total / window_s
    spans_df.rps = spans_df.throughput_total / window_s
    spans_df.bytes_per_s = spans_df.bytes_total / window_s

    # Rename timestamp to time_.
    spans_df['time_'] = spans_df['timestamp']
    # Extract the latency percentile values from the aggregate result.
    spans_df.latency_p50 = px.pluck_float64(spans_df.latency_quantiles, 'p50')
    spans_df.latency_p90 = px.pluck_float64(spans_df.latency_quantiles, 'p90')
    spans_df.latency_p99 = px.pluck_float64(spans_df.latency_quantiles, 'p99')
    return spans_df


def summarize_LET(let_df, groups):
    """ Aggregate LET values across all windows.

    Args:
    @let_df: the DataFrame with LET values.
    @groups: the columns to group over.

    Returns: The summary DF.
    """

    sum_df = let_df.groupby(groups).agg(
        latency_p50=('latency_p50', px.mean),
        latency_p90=('latency_p90', px.mean),
        latency_p99=('latency_p99', px.mean),
        rps=('rps', px.mean),
        bytes_per_s=('bytes_per_s', px.mean),
        error_rate=('error_rate', px.mean),
    )
    return sum_df


def format_resource_table(rsrc_df):
    """ Formats process stats table

    Converts nanoseconds to seconds, bytes to megabytes,
    adds a binned timestamp field to aggregate on, and adds
    the svc (k8s_object) as a semantic column.

    Args:
    @rsrc_df: the input process_stats table.

    Returns: formatted resource stats DataFrame.
    """

    bytes_per_mb = 1024.0 * 1024.0
    rsrc_df.timestamp = px.bin(rsrc_df.time_, px.seconds(window_s))
    rsrc_df.cpu_utime_s = rsrc_df.cpu_utime_ns / 1.0E9
    rsrc_df.cpu_ktime_s = rsrc_df.cpu_ktime_ns / 1.0E9
    rsrc_df.vsize_mb = rsrc_df.vsize_bytes / bytes_per_mb
    rsrc_df.rss_mb = rsrc_df.rss_bytes / bytes_per_mb
    rsrc_df.read_bytes_mb = rsrc_df.read_bytes / bytes_per_mb
    rsrc_df.write_bytes_mb = rsrc_df.write_bytes / bytes_per_mb
    rsrc_df.rchar_bytes_mb = rsrc_df.rchar_bytes / bytes_per_mb
    rsrc_df.wchar_bytes_mb = rsrc_df.wchar_bytes / bytes_per_mb
    rsrc_df[k8s_object] = rsrc_df.ctx[k8s_object]

    return rsrc_df


def calc_resource(rsrc_df):
    """ Computes CPU % and reads/writes by the k8s_object type as a timeseries.

    Args:
    @rsrc_df: the input process_stats table post-formatting.

    Returns: the metrics by k8s_object type as a timeseries.
    """

    upid_agg = rsrc_df.groupby(['upid', k8s_object, 'timestamp']).agg(
        # The following columns are all counters, so we take the minimum and maximum values.
        min_cpu_utime_s=('cpu_utime_s', px.min),
        min_cpu_ktime_s=('cpu_ktime_s', px.min),
        min_rchar_bytes_mb=('rchar_bytes_mb', px.min),
        min_wchar_bytes_mb=('wchar_bytes_mb', px.min),
        max_cpu_utime_s=('cpu_utime_s', px.max),
        max_cpu_ktime_s=('cpu_ktime_s', px.max),
        max_rchar_bytes_mb=('rchar_bytes_mb', px.max),
        max_wchar_bytes_mb=('wchar_bytes_mb', px.max),
        rss_mb=('rss_mb', px.mean),
    )

    upid_agg.cpu_utime_s = (upid_agg.max_cpu_utime_s
                            - upid_agg.min_cpu_utime_s) / window_s
    upid_agg.cpu_ktime_s = (upid_agg.max_cpu_ktime_s
                            - upid_agg.min_cpu_ktime_s) / window_s
    upid_agg.rchar_bytes_mb = (
        upid_agg.max_rchar_bytes_mb - upid_agg.min_rchar_bytes_mb) / window_s
    upid_agg.wchar_bytes_mb = (
        upid_agg.max_wchar_bytes_mb - upid_agg.min_wchar_bytes_mb) / window_s

    # For this aggregate, we sum up the values as we've already calculated the average/usage
    # for the upids already.
    k8s_agg = upid_agg.groupby([k8s_object, 'timestamp']).agg(
        cpu_utime_s=('cpu_utime_s', px.sum),
        cpu_ktime_s=('cpu_ktime_s', px.sum),
        rchar_bytes_mb=('rchar_bytes_mb', px.sum),
        wchar_bytes_mb=('wchar_bytes_mb', px.sum),
        rss_mb=('rss_mb', px.sum),
    )

    k8s_agg.cpu_pct = (k8s_agg.cpu_utime_s
                       + k8s_agg.cpu_ktime_s) * 100 / window_s

    # Get the output columns we want to plot.
    k8s_agg[split_series_name] = k8s_agg[k8s_object]
    k8s_agg['time_'] = k8s_agg['timestamp']
    return k8s_agg[[split_series_name, 'time_', 'cpu_pct', 'rchar_bytes_mb',
                    'wchar_bytes_mb', 'rss_mb']]
