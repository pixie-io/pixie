# Copyright 2018- The Pixie Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
# SPDX-License-Identifier: Apache-2.0

''' Service stats LET and local svc map

This live view calculates the latency, error rate, and throughput
of a Service and also summarizes the incoming and outgoing traffic
for a svc.

Notes:
* Setting svc is not exclusive matching at the moment. IE
  if you have two svcs 'a' and 'a-db', setting `svc = 'a'`
  will still match `a-db`
'''
import px

# ----------------------------------------------------------------
# Visualization Variables - No need to edit for basic configuration.
# ----------------------------------------------------------------
# K8s object is the abstraction to group on.
# Options are ['pod', 'service'].
k8s_object = 'service'
ns_per_ms = 1000 * 1000
ns_per_s = 1000 * ns_per_ms
# Window size to use on time_ column for bucketing.
window_ns = px.DurationNanos(10 * ns_per_s)
# Flag to filter out requests that come from an unresolvable IP.
filter_unresolved_inbound = True
# Flag to filter out health checks from the data.
filter_health_checks = True
# Flag to filter out ready checks from the data.
filter_ready_checks = True
# Flag to filter out non_k8s_traffic from the data.
filter_non_k8s_traffic = True
# The name of the incoming traffic column in the edge graphs.
src_col = 'requestor'
# The name of the outgoing traffic column in the edge graphs.
dest_col = 'responder'
# Column naem used to split data into separate time series.
# k8s_object column is renamed to this and is used in
# visualization spec.
split_series_name = 'k8s'
# The bin size to use for the latency histogram.
latency_bin_size_ns = px.DurationNanos(50 * ns_per_ms)
# ----------------------------------------------------------------


def svc_let(start_time: str, svc: px.Service):
    """ Calculates LET filtered on the svc

    Args:
    @start_time The timestamp of data to start at.
    @svc: the partial/full-name of the svc to
        calculate LET.

    Returns: DataFrame of the LET stats for svcs that
        match @svc.
    """
    df = make_http_table(start_time)
    # Calculate LET of svc(s) (k8s_object) over the time window ('timestamp')
    # after filtering for matching svcs.
    matching_df = df[px.contains(df[k8s_object], svc)]
    let_df = calc_http_LET(matching_df, [k8s_object, 'timestamp'])

    # Format and organize resulting columns.
    let_df[split_series_name] = let_df[k8s_object]
    let_df = let_df[['time_', split_series_name, 'latency_p50',
                     'latency_p90', 'latency_p99', 'error_rate',
                     'request_throughput', 'bytes_throughput']]
    return let_df


def http_code_histogram(start_time: str, svc: px.Service):
    """ Computes a histogram of HTTP status codes

    Args:
    @start_time The timestamp of data to start at.
    @svc: the partial/full-name of the svc.

    Returns: DataFrame of the HTTP status code stats for svcs that
        match @svc.
    """
    df = make_http_table(start_time)
    matching_df = df[px.contains(df[k8s_object], svc)]
    return matching_df.groupby(['resp_status']).agg(count=('latency', px.count))


def latency_histogram(start_time: str, svc: px.Service):
    """ Computes a histogram of HTTP request latency.

    Args:
    @start_time The timestamp of data to start at.
    @svc: the partial/full-name of the svc.

    Returns: DataFrame of the HTTP latency histogram for svcs that
        match @svc.
    """
    df = make_http_table(start_time)
    matching_df = df[px.contains(df[k8s_object], svc)]
    matching_df.request_latency = px.DurationNanos(px.bin(matching_df.latency,
                                                          latency_bin_size_ns))
    return matching_df.groupby('request_latency').agg(count=('resp_status', px.count))


def outgoing_edges(start_time: str, svc: px.Service):
    """ Determines the svcs that this svc makes
    requests to.

    Args:
    @start_time The timestamp of data to start at.
    @svc: the partial/full-name of the svc to
        get outgoing_edges.

    Returns: DataFrame of the svcs this svc talks to
        and the LET summary of that communication.
    """
    df = let_per_edge(start_time)
    # Filter for traffic that starts at this svc.
    outgoing_let_df = df[px.contains(
        df[src_col], svc)]

    # Group outgoing traffic by (src, dest) to get all outgoing edges.
    return summarize_LET(outgoing_let_df, [src_col, dest_col])


def incoming_edges(start_time: str, svc: px.Service):
    """ Determines the svcs that make requests to this svc.

    Args:
    @start_time The timestamp of data to start at.
    @svc: the partial/full-name of the svc to
        get incoming_edges.

    Returns: DataFrame of the svcs that talk to this svc
        and the LET summary of that communication.
    """
    df = let_per_edge(start_time)

    # Filter traffic that ends at this svc.
    incoming_let_df = df[px.contains(
        df[dest_col], svc)]

    # Group incoming traffic by (src, dest) to get all incoming edges.
    return summarize_LET(incoming_let_df, [src_col, dest_col])


def svc_graph(start_time: str, svc: px.Service):
    """ Determines the svcs that make requests to this svc.
    Like incoming_edges, but filters out empty strings in the src/dest.

    Args:
    @start_time The timestamp of data to start at.
    @svc: the partial/full-name of the svc to
        get svc_graph in.

    Returns: DataFrame of the svcs that talk to this svc
        and the LET summary of that communication.
    """

    df = incoming_edges(start_time, svc)
    return df[df[src_col] != '' and df[dest_col] != '']


# ----------------------------------------------------------------
# Utility functions:
#
# These are shared functions. We plan to support imports in v0.3,
# which will allow these functions to be shared across multiple
# scripts.
# ----------------------------------------------------------------
def make_http_table(start_time: str):
    """ Makes the HTTP table given the passed in start.

    The data necessary to compute HTTP level svc information is located in the
    http_events table. We filter and aggregate data from this table to compute the
    required metrics.

    Args:
    @start_time The timestamp of data to start at.

    Returns: DataFrame of HTTP events with formatted columns.
    """
    df = px.DataFrame(table='http_events', start_time=start_time)
    df = format_http_table(df, filter_health_checks,
                           filter_ready_checks, filter_unresolved_inbound)
    return df


def let_per_edge(start_time: str):
    """ Calculates the LET per edge of the svc graph.

    Args:
    @start_time The timestamp of data to start at.

    Returns: DataFrame of HTTP events with formatted columns.
    """

    df = make_http_table(start_time)
    # Calculate LET for each svc edge in the svc graph over each time window.
    # Each edge starts at a requester ('remote_addr') and ends at a
    # responder (k8s_object).
    edge_let_df = calc_http_LET(df, ['remote_addr', k8s_object, 'timestamp'])
    # Convert 'remote_addr' IP into a svc name.
    edge_let_df = ip_to_svc_name(edge_let_df, 'remote_addr', src_col)
    # Rename k8s_object to dest_col.
    edge_let_df[dest_col] = edge_let_df[k8s_object]
    return edge_let_df


def format_events_table(df, latency_col):
    """ Format data and add semantic columns in event tables

    Unifies latency column to 'latency', adds a binned
    timestamp field to aggregate on, and adds the svc
    (k8s_object) as a semantic column.

    Works on "mysql_events" and "http_events"

    Args:
    @df: the input events table
    @latency_col: the name of the latency column in @df.

    Returns: formatted events DataFrame
    """
    df.latency = df[latency_col]

    df.timestamp = px.bin(df.time_, window_ns)
    df[k8s_object] = df.ctx[k8s_object]
    df = df[df[k8s_object] != '']
    return df


def format_http_table(df, filter_health_checks, filter_ready_checks,
                      filter_unresolved_inbound):
    """ Formats HTTP events tables

    Runs events table universal formatting, adds a response_size,
    creates a failure field marking which requests receive an error
    status code, and optionally filters out system monitoring requests
    and partial data points.

    Args:
    @df: the input http_events table.
    @filter_health_checks: flag to filter health checks.
    @filter_ready_checks: flag to filter health checks.
    @filter_unresolved_inbound: flag to filter unresolved inbound
        requests.

    Returns: formatted HTTP events DataFrame.
    """
    df = format_events_table(df, 'latency')
    df.failure = df.resp_status >= 400
    filter_out_conds = ((df.req_path != '/healthz' or not filter_health_checks) and (
        df.req_path != '/readyz' or not filter_ready_checks)) and (
        df['remote_addr'] != '-' or not filter_unresolved_inbound)

    df = df[filter_out_conds]
    return df


def format_LET_aggs(df):
    """ Converts the result of LET windowed aggregates into expected metrics.

    Converts the result of aggregates on windows into well-formatted metrics that
    can be visualized. Latency quantile values need to be extracted from the
    quantiles struct, and then error_rate, request_throughput, and bytes_throughput
    are calculated as a function of window size.


    This function represents logic shared by LET calculators for MySQL and
    HTTP events.

    Args:
    @df: the input events table grouped into windows with aggregated
        columns 'throughput_total', 'error_rate_per_window', and 'request_throughput'

    Returns: DataFrame with formatted LET metrics.
    """
    df.latency_p50 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p50')))
    df.latency_p90 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p90')))
    df.latency_p99 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p99')))
    df['time_'] = df['timestamp']
    df.request_throughput = df.throughput_total / window_ns
    df.bytes_throughput = df.bytes_total / window_ns
    df.error_rate = df.error_rate_per_window * df.request_throughput / px.DurationNanos(1)

    return df


def calc_http_LET(df, groups):
    """ Calculates Latency, Error Rate, and Throughput on HTTP events.

    Calculates latency, error rate, and throughput aggregated over
    @groups. Throughput is represented by two values: request_throughput, and bytes_throughput.

    Args:
    @df: the input http_events table.
    @groups: the list of columns to group on. 'timestamp' must be a a group
        or this will fail.

    Returns: The LET DataFrame.
    """
    # Aggregate values over the window.
    df = df.groupby(groups).agg(
        latency_quantiles=('latency', px.quantiles),
        error_rate_per_window=('failure', px.mean),
        throughput_total=('latency', px.count),
        bytes_total=('resp_body_size', px.sum)
    )

    # Format the result of LET aggregates into proper scalar formats and
    # time series.
    df = format_LET_aggs(df)
    return df


def ip_to_svc_name(df, ip_col, svc_col_name):
    """ Map IP to svc name.

    Maps IP values stored in @ip_col into svc names to store into
    @svc_col_name.

    Args:
    @df: the input dataframe.
    @ip_col: the IP column to map from.
    @svc_col_name: the column name to assign the new svc values.

    Returns: DataFrame with the svc_col added.
    """
    pod_id = 'pod_id'
    df[pod_id] = px.ip_to_pod_id(df[ip_col])
    df[svc_col_name] = px.pod_id_to_service_name(df[pod_id])
    return df.drop(pod_id)


def summarize_LET(let_df, groups):
    """ Aggregate LET values across all windows.

    Args:
    @let_df: the DataFrame with LET values.
    @groups: the columns to group over.

    Returns: The summary DF.
    """

    df = let_df.groupby(groups).agg(
        request_throughput=('request_throughput', px.mean),
        bytes_throughput=('bytes_throughput', px.mean),
        error_rate=('error_rate', px.mean),
    )
    return df
