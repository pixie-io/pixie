# Copyright 2018- The Pixie Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
# SPDX-License-Identifier: Apache-2.0

''' PostgreSQL Pod LET metrics

This live view calculates the latency, error rate, and throughput
for each connection to a PostgreSQL database pod.
'''
import px

# ----------------------------------------------------------------
# Visualization Variables - No need to edit for basic configuration.
# ----------------------------------------------------------------
ns_per_ms = 1000 * 1000
ns_per_s = 1000 * ns_per_ms
# Window size to use on time_ column for bucketing.
window_ns = px.DurationNanos(10 * ns_per_s)
# The bin size to use for the latency histogram.
latency_bin_size_ns = px.DurationNanos(50 * ns_per_ms)
# ----------------------------------------------------------------


# ----------------------------------------------------------------
# Visualization functions:
#
# These functions are formatted and ready for use in
# the visualization specification, vis.json.
# ----------------------------------------------------------------
def pod_pgsql_let(start_time: str, pod: px.Pod):
    ''' Calculate LET time-series for PostgreSQL traffic per connection to
    a PostgreSQL database pod.

    Calculates latency and throughput for each pod's
    connection to a PostgreSQL database pod.

    @start_time The timestamp of data to start at.
    @pod: the partial/full-name of the pod to monitor PostgreSQL LET.

    Returns: Returns the DataFrame containing LET time-series for PostgreSQL
        traffic to a PostgreSQL database pod.
    '''
    df = pgsql_let_per_pod(start_time, pod, ['timestamp', 'destination'])

    return df[['time_', 'destination', 'latency_p50', 'latency_p90',
              'latency_p99', 'request_throughput']]


def summary_pgsql_let(start_time: str, pod: px.Pod):
    ''' Calculate LET summary for PostgreSQL traffic per connection to
    a PostgreSQL database pod.

    Calculates latency and throughput for each
    connection to a PostgreSQL database pod.

    @start_time The timestamp of data to start at.
    @pod: the partial/full-name of the pod to monitor PostgreSQL LET.

    Returns: Returns the DataFrame containing LET time-series for PostgreSQL
    traffic to a PostgreSQL database pod.
    '''

    df = pgsql_let_per_pod(start_time, pod, ['timestamp', 'source', 'destination',
                                             'is_source_pod_type', 'is_dest_pod_type',
                                             'namespace'])
    summary_df = summarize_LET(df, ['source', 'destination', 'is_source_pod_type',
                                    'is_dest_pod_type', 'namespace'])
    summary_df_links = add_source_dest_links(summary_df, start_time)

    return summary_df_links[['source', 'destination', 'request_throughput', 'latency',
                             'total_requests']]


def latency_histogram(start_time: str, pod: px.Pod):
    ''' Computes a histogram of PostgreSQL request latency.

    Args:
    @start_time The timestamp of data to start at.
    @svc: the partial/full-name of the svc.

    Returns: DataFrame of the PostgreSQL latency histogram for svcs that
        match @svc.
    '''
    # The data necessary to compute PostgreSQL LET information is located in the
    # pgsql_events table. We filter and aggregate data from this table to compute the
    # required metrics.
    df = px.DataFrame(table='pgsql_events', start_time=start_time)
    df = format_pgsql_table(df)

    # Calculate LET of pod(s) (k8s_object) connection to PostgreSQL connections
    # over the time window ('timestamp') after filtering for matching svcs.
    matching_df = df[px.contains(df.source, pod) or px.contains(df.destination, pod)]

    matching_df.request_latency = px.DurationNanos(px.bin(matching_df.latency,
                                                          latency_bin_size_ns))
    return matching_df.groupby('request_latency').agg(count=('time_', px.count))


# ----------------------------------------------------------------
# Utility functions:
#
# These are shared functions. We plan to support imports in v0.3,
# which will allow these functions to be shared across multiple
# scripts.
# ----------------------------------------------------------------
def pgsql_let_per_pod(start_time: str, pod: px.Pod, groups):
    ''' Calculate LET time-series for PostgreSQL traffic per connection to
    a PostgreSQL database pod.

    Calculates latency and throughput for each connection to a
    PostgreSQL database pod.

    @start_time The timestamp of data to start at.
    @pod: the partial/full-name of the pod to monitor PostgreSQL LET.

    Returns: Returns the DataFrame containing LET time-series for PostgreSQL
    traffic to a PostgreSQL database pod.
    '''
    # The data necessary to compute PostgreSQL LET information is located in the
    # pgsql_events table. We filter and aggregate data from this table to compute the
    # required metrics.
    df = px.DataFrame(table='pgsql_events', start_time=start_time)
    df = format_pgsql_table(df)

    # Calculate LET of pod(s) (k8s_object) connection to PostgreSQL connections
    # over the time window ('timestamp') after filtering for matching svcs.
    matching_df = df[px.contains(df.source, pod) or px.contains(df.destination, pod)]

    let_df = calc_pgsql_LET(matching_df, groups)

    return let_df


def format_events_table(df, latency_col):
    ''' Format data and add semantic columns in event tables

    Unifies latency column to 'latency_ms', adds a binned
    timestamp field to aggregate on, and adds the svc
    (k8s_object) as a semantic column.

    Works on 'pgsql_events' and 'http_events'

    Args:
    @df: the input events table
    @latency_col: the name of the latency column in @df.

    Returns: formatted events DataFrame
    '''
    df.latency = df[latency_col]
    df.timestamp = px.bin(df.time_, window_ns)
    df = df[df['pod'] != '']

    return df


def format_pgsql_table(df):
    ''' Formats pgsql_events tables

    Args:
    @df: the input pgsql_events table.

    Returns: formatted pgsql_events DataFrame.
    '''
    # Add source, destination columns.
    df = add_source_dest_columns(df)

    df = format_events_table(df, 'latency')
    return df


def format_LET_aggs(df):
    ''' Converts the result of LET windowed aggregates into expected metrics.

    Converts the result of aggregates on windows into well-formatted metrics that
    can be visualized. Latency quantile values need to be extracted from the
    quantiles struct, and then request_throughput is calculated as
    a function of window size.


    This function represents logic shared by LET calculators for PostgreSQL and
    HTTP events.

    Args:
    @df: the input events table grouped into windows with aggregated
        columns 'throughput_total' and 'request_throughput'

    Returns: DataFrame with formatted LET metrics.
    '''
    df.latency_p50 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p50')))
    df.latency_p90 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p90')))
    df.latency_p99 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p99')))
    df['time_'] = df['timestamp']
    df.request_throughput = df.throughput_total / window_ns

    return df


def calc_pgsql_LET(df, groups):
    ''' Calculates Latency, Error Rate, and Throughput on PostgreSQL events.

    Calculates latency, error rate, and throughput aggregated over
    @groups.

    Args:
    @df: the input pgsql_events table.
    @groups: the list of columns to group on. 'timestamp' must be a a group
        or this will fail.

    Returns: The LET DataFrame.
    '''
    # All requests for errors and throughput
    df = df.groupby(groups).agg(
        latency_quantiles=('latency', px.quantiles),
        throughput_total=('latency', px.count)
    )

    # Format the result of LET aggregates into proper scalar formats and
    # time series.
    df = format_LET_aggs(df)
    return df


def summarize_LET(let_df, groups):
    ''' Aggregate LET values across all windows.

    Args:
    @let_df: the DataFrame with LET values.
    @groups: the columns to group over.

    Returns: The summary DF.
    '''
    df = let_df.groupby(groups).agg(
        request_throughput=('request_throughput', px.mean),
        total_requests=('throughput_total', px.sum),
        latency=('latency_p50', px.mean)
    )
    return df


def add_source_dest_columns(df):
    ''' Add source and destination columns for the PostgreSQL request.

    PostgreSQL requests are traced server-side (trace_role==2), unless the server is
    outside of the cluster in which case the request is traced client-side (trace_role==1).

    When trace_role==2, the PostgreSQL request source is the remote_addr column
    and destination is the pod column. When trace_role==1, the PostgreSQL request
    source is the pod column and the destination is the remote_addr column.

    Input DataFrame must contain trace_role, upid, remote_addr columns.
    '''
    df.pod = df.ctx['pod']
    df.namespace = df.ctx['namespace']

    # If remote_addr is a pod, get its name. If not, use IP address.
    df.ra_pod = px.pod_id_to_pod_name(px.ip_to_pod_id(df.remote_addr))
    df.is_ra_pod = df.ra_pod != ''
    df.ra_name = px.select(df.is_ra_pod, df.ra_pod, df.remote_addr)

    df.is_server_tracing = df.trace_role == 2
    df.is_source_pod_type = px.select(df.is_server_tracing, df.is_ra_pod, True)
    df.is_dest_pod_type = px.select(df.is_server_tracing, True, df.is_ra_pod)

    # Set source and destination based on trace_role.
    df.source = px.select(df.is_server_tracing, df.ra_name, df.pod)
    df.destination = px.select(df.is_server_tracing, df.pod, df.ra_name)

    # Filter out messages with empty source / destination.
    df = df[df.source != '']
    df = df[df.destination != '']

    df = df.drop(['ra_pod', 'is_ra_pod', 'ra_name', 'is_server_tracing'])

    return df


def add_source_dest_links(df, start_time: str):
    ''' Modifies the source and destination columns to display deeplinks in the UI.
    Clicking on a pod name in either column will run the px/pod script for that pod.
    Clicking on an IP address, will run the px/ip script showing all network connections
    to/from that IP address.

    Input DataFrame must contain source, destination, is_source_pod_type,
    is_dest_pod_type, and namespace columns.
    '''

    # Source linking. If source is a pod, link to px/pod. If an IP addr, link to px/net_flow_graph.
    df.src_pod_link = px.script_reference(df.source, 'px/pod', {
        'start_time': start_time,
        'pod': df.source
    })
    df.src_link = px.script_reference(df.source, 'px/ip', {
        'start_time': start_time,
        'ip': df.source,
    })
    df.source = px.select(df.is_source_pod_type, df.src_pod_link, df.src_link)

    # If destination is a pod, link to px/pod. If an IP addr, link to px/net_flow_graph.
    df.dest_pod_link = px.script_reference(df.destination, 'px/pod', {
        'start_time': start_time,
        'pod': df.destination
    })
    df.dest_link = px.script_reference(df.destination, 'px/ip', {
        'start_time': start_time,
        'ip': df.destination,
    })
    df.destination = px.select(df.is_dest_pod_type, df.dest_pod_link, df.dest_link)

    df = df.drop(['src_pod_link', 'src_link', 'is_source_pod_type', 'dest_pod_link',
                  'dest_link', 'is_dest_pod_type'])

    return df
