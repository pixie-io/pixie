# Copyright (c) Pixie Labs, Inc.
# Licensed under the Apache License, Version 2.0 (the "License")

''' MySQL Pod LET metrics

This live view calculates the latency, error rate, and throughput
for each connection to a MySQL database pod.
'''

import px

# ----------------------------------------------------------------
# Visualization Variables - No need to edit for basic configuration.
# ----------------------------------------------------------------
ns_per_ms = 1000 * 1000
ns_per_s = 1000 * ns_per_ms
# Window size to use on time_ column for bucketing.
window_ns = px.DurationNanos(10 * ns_per_s)
# None response code returns on close() of MySQL connection.
none_response_code = 1
# Flag to filter out MySQL responses where no data is returned.
filter_responses_with_none_code = True
# The bin size to use for the latency histogram.
latency_bin_size_ns = px.DurationNanos(5 * ns_per_ms)
# ----------------------------------------------------------------


# ----------------------------------------------------------------
# Visualization functions:
#
# These functions are formatted and ready for use in
# the visualization specification, vis.json.
# ----------------------------------------------------------------
def pod_mysql_let(start: str, pod: px.Pod):
    ''' Calculate LET time-series for MySQL traffic per connection to
    a MySQL database pod.

    Calculates latency, error_rate, and throughput for each pod's
    connection to a MySQL database pod.

    @start: The timestamp of data to start at.
    @pod: the partial/full-name of the pod to monitor MySQL LET.

    Returns: Returns the DataFrame containing LET time-series for MySQL
        traffic to a MySQL database pod.
    '''
    df = mysql_let_per_pod(start, pod, ['timestamp', 'destination'])

    return df[['time_', 'destination', 'latency_p50', 'latency_p90',
              'latency_p99', 'error_rate', 'request_throughput']]


def summary_mysql_let(start: str, pod: px.Pod):
    ''' Calculate LET summary for MySQL traffic per connection to
    a MySQL database pod.

    Calculates latency,  error_rate, and throughput for each
    connection to a MySQL database pod.

    @start: The timestamp of data to start at.
    @pod: the partial/full-name of the pod to monitor MySQL LET.

    Returns: Returns the DataFrame containing LET time-series for MySQL
    traffic to a MySQL database pod.
    '''

    df = mysql_let_per_pod(start, pod, ['timestamp', 'source', 'destination', 'is_source_pod_type',
                                        'is_dest_pod_type', 'namespace'])
    summary_df = summarize_LET(df, ['source', 'destination', 'is_source_pod_type', 'is_dest_pod_type',
                                    'namespace'])
    summary_df_links = add_source_dest_links(summary_df, start)

    return summary_df_links[['source', 'destination', 'request_throughput', 'error_rate',
                             'latency', 'total_requests']]


def latency_histogram(start: str, pod: px.Pod):
    ''' Computes a histogram of MySQL request latency.

    Args:
    @start: The timestamp of data to start at.
    @svc: the partial/full-name of the svc.

    Returns: DataFrame of the MySQL latency histogram for svcs that
        match @svc.
    '''
    # The data necessary to compute MySQL LET information is located in the
    # mysql_events table. We filter and aggregate data from this table to compute the
    # required metrics.
    df = px.DataFrame(table='mysql_events', start_time=start)
    df = format_mysql_table(df, filter_responses_with_none_code)

    # Calculate LET of pod(s) (k8s_object) connection to MySQL connections
    # over the time window ('timestamp') after filtering for matching svcs.
    matching_df = df[px.contains(df.source, pod) or px.contains(df.destination, pod)]

    matching_df.request_latency = px.DurationNanos(px.bin(matching_df.latency,
                                                          latency_bin_size_ns))
    return matching_df.groupby('request_latency').agg(count=('time_', px.count))


# ----------------------------------------------------------------
# Utility functions:
#
# These are shared functions. We plan to support imports in v0.3,
# which will allow these functions to be shared across multiple
# scripts.
# ----------------------------------------------------------------
def mysql_let_per_pod(start: str, pod: px.Pod, groups):
    ''' Calculate LET time-series for MySQL traffic per connection to
    a MySQL database pod.

    Calculates latency, error_rate, and throughput for each connection to a
    MySQL database pod.

    @start: The timestamp of data to start at.
    @pod: the partial/full-name of the pod to monitor MySQL LET.

    Returns: Returns the DataFrame containing LET time-series for MySQL
    traffic to a MySQL database pod.
    '''
    # The data necessary to compute MySQL LET information is located in the
    # mysql_events table. We filter and aggregate data from this table to compute the
    # required metrics.
    df = px.DataFrame(table='mysql_events', start_time=start)
    df = format_mysql_table(df, filter_responses_with_none_code)

    # Calculate LET of pod(s) (k8s_object) connection to MySQL connections
    # over the time window ('timestamp') after filtering for matching svcs.
    matching_df = df[px.contains(df.source, pod) or px.contains(df.destination, pod)]

    let_df = calc_mysql_LET(matching_df, groups)

    return let_df


def format_events_table(df, latency_col):
    ''' Format data and add semantic columns in event tables

    Unifies latency column to 'latency_ms', adds a binned
    timestamp field to aggregate on, and adds the svc
    (k8s_object) as a semantic column.

    Works on 'mysql_events' and 'http_events'

    Args:
    @df: the input events table
    @latency_col: the name of the latency column in @df.

    Returns: formatted events DataFrame
    '''
    df.latency = df[latency_col]
    df.timestamp = px.bin(df.time_, window_ns)
    df = df[df['pod'] != '']

    return df


def format_mysql_table(df, filter_responses_with_none_code):
    ''' Formats mysql_events tables

    Runs events table universal formatting, creates a failure field
    marking which requests receive an error status code, and
    optionally filters out responses with "None" response
    error code if @filter_responses_with_none_code is true.

    Args:
    @df: the input mysql_events table.
    @filter_responses_with_none_code: flag to filter out MySQL
        responses where no data is returned.
    Returns: formatted mysql_events DataFrame.
    '''
    # Add source, destination columns.
    df = add_source_dest_columns(df)

    df = format_events_table(df, 'latency')
    df.failure = df['resp_status'] == 3
    df.resp_size = px.Bytes(px.length(df.resp_body))

    df = df[df.resp_status
            != none_response_code or not filter_responses_with_none_code]
    return df


def format_LET_aggs(df):
    ''' Converts the result of LET windowed aggregates into expected metrics.

    Converts the result of aggregates on windows into well-formatted metrics that
    can be visualized. Latency quantile values need to be extracted from the
    quantiles struct, and then error_rate, request_throughput and bytes_per_ns are calculated as
    a function of window size.


    This function represents logic shared by LET calculators for MySQL and
    HTTP events.

    Args:
    @df: the input events table grouped into windows with aggregated
        columns 'throughput_total', 'error_rate_per_window', and 'request_throughput'

    Returns: DataFrame with formatted LET metrics.
    '''
    df.latency_p50 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p50')))
    df.latency_p90 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p90')))
    df.latency_p99 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p99')))
    df['time_'] = df['timestamp']
    df.request_throughput = df.throughput_total / window_ns
    df.bytes_per_ns = df.bytes_total / window_ns
    df.error_rate = df.error_rate_per_window * df.request_throughput / px.DurationNanos(1)

    return df


def calc_mysql_LET(df, groups):
    ''' Calculates Latency, Error Rate, and Throughput on MySQL events.

    Calculates latency, error rate, and throughput aggregated over
    @groups.

    Args:
    @df: the input mysql_events table.
    @groups: the list of columns to group on. 'timestamp' must be a a group
        or this will fail.

    Returns: The LET DataFrame.
    '''
    # All requests for errors and throughput
    df = df.groupby(groups).agg(
        latency_quantiles=('latency', px.quantiles),
        bytes_total=('resp_size', px.sum),
        error_rate_per_window=('failure', px.mean),
        throughput_total=('latency', px.count)
    )

    # Format the result of LET aggregates into proper scalar formats and
    # time series.
    df = format_LET_aggs(df)
    return df


def summarize_LET(let_df, groups):
    ''' Aggregate LET values across all windows.

    Args:
    @let_df: the DataFrame with LET values.
    @groups: the columns to group over.

    Returns: The summary DF.
    '''
    df = let_df.groupby(groups).agg(
        request_throughput=('request_throughput', px.mean),
        bytes_per_ns=('bytes_per_ns', px.mean),
        error_rate=('error_rate', px.mean),
        total_requests=('throughput_total', px.sum),
        latency=('latency_p50', px.mean)
    )
    return df


def add_source_dest_columns(df):
    ''' Add source and destination columns for the MySQL request.

    MySQL requests are traced server-side (trace_role==2), unless the server is
    outside of the cluster in which case the request is traced client-side (trace_role==1).

    When trace_role==2, the MySQL request source is the remote_addr column
    and destination is the pod column. When trace_role==1, the MySQL request
    source is the pod column and the destination is the remote_addr column.

    Input DataFrame must contain trace_role, upid, remote_addr columns.
    '''
    df.pod = df.ctx['pod']
    df.namespace = df.ctx['namespace']

    # TODO: remove hack to get around PP-2445.
    df = df.head(1000000000)

    # If remote_addr is a pod, get its name. If not, use IP address.
    df.ra_pod = px.pod_id_to_pod_name(px.ip_to_pod_id(df.remote_addr))
    df.is_ra_pod = df.ra_pod != ''
    df.ra_name = px.select(df.is_ra_pod, df.ra_pod, df.remote_addr)

    df.is_server_tracing = df.trace_role == 2
    df.is_source_pod_type = px.select(df.is_server_tracing, df.is_ra_pod, True)
    df.is_dest_pod_type = px.select(df.is_server_tracing, True, df.is_ra_pod)

    # Set source and destination based on trace_role.
    df.source = px.select(df.is_server_tracing, df.ra_name, df.pod)
    df.destination = px.select(df.is_server_tracing, df.pod, df.ra_name)

    # Filter out messages with empty source / destination.
    df = df[df.source != '']
    df = df[df.destination != '']

    df = df.drop(['ra_pod', 'is_ra_pod', 'ra_name', 'is_server_tracing'])

    return df


def add_source_dest_links(df, start: str):
    ''' Modifies the source and destination columns to display deeplinks in the UI.
    Clicking on a pod name in either column will run the px/pod script for that pod.
    Clicking on an IP address, will run the px/net_flow_graph script showing all
    network connections to/from that address.

    Input DataFrame must contain source, destination, is_source_pod_type,
    is_dest_pod_type, and namespace columns.
    '''

    # Source linking. If source is a pod, link to px/pod. If an IP addr, link to px/net_flow_graph.
    df.src_pod_link = px.script_reference(df.source, 'px/pod', {
        'start_time': start,
        'pod': df.source
    })
    df.src_link = px.script_reference(df.source, 'px/net_flow_graph', {
        'start_time': start,
        'namespace': df.namespace,
        'from_entity_filter': df.source,
        'to_entity_filter': '',
        'throughput_filter': '0.0'
    })
    df.source = px.select(df.is_source_pod_type, df.src_pod_link, df.src_link)

    # If destination is a pod, link to px/pod. If an IP addr, link to px/net_flow_graph.
    df.dest_pod_link = px.script_reference(df.destination, 'px/pod', {
        'start_time': start,
        'pod': df.destination
    })
    df.dest_link = px.script_reference(df.destination, 'px/net_flow_graph', {
        'start_time': start,
        'namespace': df.namespace,
        'from_entity_filter': '',
        'to_entity_filter': df.destination,
        'throughput_filter': '0.0'
    })
    df.destination = px.select(df.is_dest_pod_type, df.dest_pod_link, df.dest_link)

    df = df.drop(['src_pod_link', 'src_link', 'is_source_pod_type', 'dest_pod_link',
                  'dest_link', 'is_dest_pod_type'])

    return df
