# Copyright (c) Pixie Labs, Inc.
# Licensed under the Apache License, Version 2.0 (the "License")

''' MySQL Pod LET metrics

This live view calculates the latency, error rate, and throughput
of a pod's MySQL requests.

Notes:
* We disable tracking close() responses because of the high rate of
  false positives. If you are ok with false positives, set
  @filter_responses_with_none_code to equal False
'''
import px

# ----------------------------------------------------------------
# Visualization Variables - No need to edit for basic configuration.
# ----------------------------------------------------------------
# K8s object is the abstraction to group on.
# Options are ['pod', 'service'].
k8s_object = 'pod'
ns_per_ms = 1000 * 1000
ns_per_s = 1000 * ns_per_ms
# Window size to use on time_ column for bucketing.
window_ns = px.DurationNanos(10 * ns_per_s)
# None response code returns on close() of MySQL connection.
none_response_code = 1
# Flag to filter out MySQL responses where no data is returned.
filter_responses_with_none_code = True
# Column naem used to split data into separate time series.
# k8s_object column is renamed to this and is used in
# visualization spec.
split_series_name = 'k8s'
# This is the name of the column corresponding to the MySQL IP.
ip_col_name = 'MySQL IP'
# Temporary way to ensure px.Pod works as expected.
px.Pod = str
# The bin size to use for the latency histogram.
latency_bin_size_ns = px.DurationNanos(5 * ns_per_ms)
# ----------------------------------------------------------------


# ----------------------------------------------------------------
# Visualization functions:
#
# These functions are formatted and ready for use in
# the visualization speciciation, vis.json.
# ----------------------------------------------------------------
def pod_mysql_let(start: str, pod: px.Pod):
    """ Calculate LET time-series for MySQL traffic per Pod, database pair.

    Calculates latency, error_rate, and throughput for each pod's
    connection to MySQL databases.

    @start: The timestamp of data to start at.
    @pod: the partial/full-name of the pod to monitor MySQL LET.

    Returns: Returns the DataFrame contiaining LET time-series for MySQL
        traffic for each database Pods talk to.
    """
    df = mysql_let_per_pod(start, pod, ['timestamp', k8s_object])
    return df['time_', split_series_name, 'latency_p50',
              'latency_p90', 'latency_p99', 'error_rate', 'request_throughput']


def summary_mysql_let(start: str, pod: px.Pod):
    """ Calculate LET summary for MySQL traffic per Pod, database pair.

    Calculates latency, error_rate, and throughput for each pod's
    connection to MySQL databases.

    @start: The timestamp of data to start at.
    @pod: the partial/full-name of the pod to monitor MySQL LET.

    Returns: Returns the DataFrame contiaining LET time-series for MySQL
        traffic for each database Pods talk to.
    """
    df = mysql_let_per_pod(start, pod, ['timestamp', k8s_object, 'remote_addr'])
    df[ip_col_name] = df.remote_addr
    summary_df = summarize_LET(df, [k8s_object, ip_col_name])
    return summary_df[[k8s_object, ip_col_name, "request_throughput",
                       "error_rate", "latency", "total_requests"]]


def latency_histogram(start: str, pod: px.Pod):
    """ Computes a histogram of HTTP request latency.

    Args:
    @start: The timestamp of data to start at.
    @svc: the partial/full-name of the svc.

    Returns: DataFrame of the HTTP latency histogram for svcs that
        match @svc.
    """
    # The data necessary to compute MySQL LET information is located in the
    # mysql_events table. We filter and aggregate data from this table to compute the
    # required metrics.
    df = px.DataFrame(table='mysql_events', start_time=start)
    df = format_mysql_table(df, filter_responses_with_none_code)

    # Calculate LET of pod(s) (k8s_object) connection to MySQL conections
    # over the time window ('timestamp') after filtering for matching svcs.
    matching_df = df[px.contains(df[k8s_object], pod)]

    matching_df.request_latency = px.DurationNanos(px.bin(matching_df.latency,
                                                          latency_bin_size_ns))
    return matching_df.groupby('request_latency').agg(count=('time_', px.count))


# ----------------------------------------------------------------
# Utility functions:
#
# These are shared functions. We plan to support imports in v0.3,
# which will allow these functions to be shared across multiple
# scripts.
# ----------------------------------------------------------------
def mysql_let_per_pod(start: str, pod: px.Pod, groups):
    """ Calculate LET time-series for MySQL traffic per Pod, database pair.

    Calculates latency, error_rate, and throughput for each pod's
    connection to MySQL databases.

    @start: The timestamp of data to start at.
    @pod: the partial/full-name of the pod to monitor MySQL LET.
    @groups: Other groups to group by.

    Returns: Returns the DataFrame contiaining LET time-series for MySQL
        traffic for each database Pods talk to.
    """
    # The data necessary to compute MySQL LET information is located in the
    # mysql_events table. We filter and aggregate data from this table to compute the
    # required metrics.
    df = px.DataFrame(table='mysql_events', start_time=start)
    df = format_mysql_table(df, filter_responses_with_none_code)

    # Calculate LET of pod(s) (k8s_object) connection to MySQL conections
    # over the time window ('timestamp') after filtering for matching svcs.
    matching_df = df[px.contains(df[k8s_object], pod)]
    let_df = calc_mysql_LET(matching_df, groups)
    let_df[split_series_name] = let_df[k8s_object]
    return let_df


def format_events_table(df, latency_col):
    """ Format data and add semantic columns in event tables

    Unifies latency column to 'latency', adds a binned
    timestamp field to aggregate on, and adds the svc
    (k8s_object) as a semantic column.

    Works on "mysql_events" and "http_events"

    Args:
    @df: the input events table
    @latency_col: the name of the latency column in @df.

    Returns: formatted events DataFrame
    """
    df.latency = df[latency_col]

    df.timestamp = px.bin(df.time_, window_ns)
    df[k8s_object] = df.ctx[k8s_object]
    df = df[df[k8s_object] != '']
    return df


def format_mysql_table(df, filter_responses_with_none_code):
    """ Formats mysql_events tables

    Runs events table universal formatting, creates a failure field
    marking which requests receive an error status code, and
    optionally filters out responses with "None" response
    error code if @filter_responses_with_none_code is true.

    Args:
    @df: the input mysql_events table.
    @filter_responses_with_none_code: flag to filter out MySQL
        responses where no data is returned.

    Returns: formatted mysql_events DataFrame.
    """
    df = format_events_table(df, 'latency')
    df.failure = df['resp_status'] == 3
    df.resp_size = px.Bytes(px.length(df.resp_body))

    df = df[df.resp_status
            != none_response_code or not filter_responses_with_none_code]
    return df


def format_LET_aggs(df):
    """ Converts the result of LET windowed aggregates into expected metrics.

    Converts the result of aggregates on windows into well-formatted metrics that
    can be visualized. Latency quantile values need to be extracted from the
    quantiles struct, and then error_rate, request_throughput, and bytes_per_ns are calculated as
    a function of window size.


    This function represents logic shared by LET calculators for MySQL and
    HTTP events.

    Args:
    @df: the input events table grouped into windows with aggregated
        columns 'throughput_total', 'error_rate_per_window', and 'request_throughput'

    Returns: DataFrame with formatted LET metrics.
    """

    df.latency_p50 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p50')))
    df.latency_p90 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p90')))
    df.latency_p99 = px.DurationNanos(px.floor(px.pluck_float64(df.latency_quantiles, 'p99')))
    df['time_'] = df['timestamp']
    df.request_throughput = df.throughput_total / window_ns
    df.bytes_per_ns = df.bytes_total / window_ns
    df.error_rate = df.error_rate_per_window * df.request_throughput / px.DurationNanos(1)

    return df


def calc_mysql_LET(df, groups):
    """ Calculates Latency, Error Rate, and Throughput on MySQL events.

    Calculates latency, error rate, and throughput aggregated over
    @groups.

    Args:
    @df: the input mysql_events table.
    @groups: the list of columns to group on. 'timestamp' must be a a group
        or this will fail.

    Returns: The LET DataFrame.
    """
    # All requests for errors and throughput
    et = df.groupby(groups).agg(
        throughput_total=('latency', px.count),
        error_rate_per_window=('failure', px.mean),
    )

    filt_df = df[df.resp_status != 1]
    # Calculate latency on all requests that return or return an err.
    lcy = filt_df.groupby(groups).agg(
        latency_quantiles=('latency', px.quantiles),
        bytes_total=('resp_size', px.sum)
    )
    # Left join because et's groups are a strict superset of lcy.
    df = et.merge(lcy, how='left', left_on=groups,
                  right_on=groups, suffixes=['', '_x'])

    # Format the result of LET aggregates into proper scalar formats and
    # time series.
    df = format_LET_aggs(df)
    return df


def ip_to_svc_name(df, ip_col, svc_col_name):
    """ Map IP to service name.

    Maps IP values stored in @ip_col into svc names to store into
    @svc_col_name.

    Args:
    @df: the input dataframe.
    @ip_col: the IP column to map from.
    @svc_col_name: the column name to assign the new svc values.

    Returns: DataFrame with the svc_col added.
    """
    pod_id = 'pod_id'
    df[pod_id] = px.ip_to_pod_id(df[ip_col])
    df[svc_col_name] = px.pod_id_to_service_name(df[pod_id])
    return df.drop(pod_id)


def summarize_LET(let_df, groups):
    """ Aggregate LET values across all windows.

    Args:
    @let_df: the DataFrame with LET values.
    @groups: the columns to group over.

    Returns: The summary DF.
    """
    df = let_df.groupby(groups).agg(
        request_throughput=('request_throughput', px.mean),
        bytes_per_ns=('bytes_per_ns', px.mean),
        error_rate=('error_rate', px.mean),
        total_requests=('throughput_total', px.sum),
        latency=('latency_p50', px.mean),
    )
    return df
